{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqQU75b6sEP-"
   },
   "source": [
    "# Global Terrorism Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awa52qQpsEQb"
   },
   "source": [
    "# Predictive Modeling -> Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pI-vjLmvyI5",
    "outputId": "3699e615-7ab3-4355-c4c2-21b04f1cf8b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nynv5Ib7wHKF"
   },
   "source": [
    "### Read Downsampled Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QjOYUqnfwLOw"
   },
   "outputs": [],
   "source": [
    "def convert_text_to_sequences(df_train, df_test):\n",
    "    # Convert text to sequences for each dataset\n",
    "    y_train = np.array(df_train['enc_group'])\n",
    "    X_train = df_train.drop(columns=[\"enc_group\"])\n",
    "\n",
    "    #y_val =np.array(df_val['enc_group'])\n",
    "    #X_val = df_val.drop(columns=[\"enc_group\"])\n",
    "\n",
    "    y_test = np.array(df_test['enc_group'])\n",
    "    X_test = df_test.drop(columns=[\"enc_group\"])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def read_and_split_data(partitions, paths):\n",
    "    train_datasets = []\n",
    "    test_datasets= []\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    X_tests = []\n",
    "    y_tests = []\n",
    "    # Loop through each partition to process data\n",
    "    for i, partition in enumerate(partitions):\n",
    "        print(\"ITERATION: \", i)\n",
    "        # Load train and validation data\n",
    "        data = pd.read_csv(paths[i], encoding='ISO-8859-1')\n",
    "        data = data.drop(columns=['attack_date'])\n",
    "        y = np.array(data[\"enc_group\"])\n",
    "        x = data.drop(columns=[\"enc_group\"])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "        #val_data = pd.read_csv(val_paths[i], encoding='ISO-8859-1')\n",
    "        #combined = pd.concat([train_data, val_data])\n",
    "        #print(combined.isnull().sum())\n",
    "        \n",
    "        # Concatenate train and validation data\n",
    "        #train_data = combined\n",
    "\n",
    "        # Load and use the test data directly\n",
    "        #test_data = pd.read_csv(test_paths[i], encoding='ISO-8859-1')\n",
    "        #combined = combined.drop(columns=[\"enc_weapon_subtype\"])\n",
    "        #test_data = test_data.drop(columns=[\"enc_weapon_subtype\"])\n",
    "\n",
    "        #train_datasets.append(train_data)\n",
    "        #test_datasets.append(test_data)\n",
    "        #X_train, y_train, X_test, y_test = convert_text_to_sequences(combined, test_data)\n",
    "\n",
    "        if 'entity' in X_train.columns:\n",
    "            X_train.drop(columns='entity', inplace=True)\n",
    "        if 'entity' in X_test.columns:\n",
    "            X_test.drop(columns='entity', inplace=True)       \n",
    "        median_train = X_train.median()\n",
    "        median_test = X_test.median()\n",
    "        X_train = X_train.fillna(median_train)\n",
    "        X_test = X_test.fillna(median_test)\n",
    "        \n",
    "        X_trains.append(X_train)\n",
    "        y_trains.append(y_train)\n",
    "        X_tests.append(X_test)\n",
    "        y_tests.append(y_test)\n",
    "\n",
    "        print(f'Data for {partition} processed.')\n",
    "\n",
    "    return X_trains, y_trains, X_tests, y_tests\n",
    "    #print(train_datasets[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION:  0\n",
      "Data for data_1970_80 processed.\n",
      "ITERATION:  1\n",
      "Data for data_1981_95 processed.\n",
      "ITERATION:  2\n",
      "Data for data_2013_14 processed.\n",
      "ITERATION:  3\n",
      "Data for data_2015_17 processed.\n"
     ]
    }
   ],
   "source": [
    "partitions = [\"data_1970_80\", \"data_1981_95\", \"data_2013_14\", \"data_2015_17\"]\n",
    "#partitions = [\"data_1970_80\"]\n",
    "train_paths = []\n",
    "test_paths = []\n",
    "val_paths = []\n",
    "paths = []\n",
    "for partition in partitions:\n",
    "    #train_paths.append(f'../original/{partition}/down_sampled/train/{partition}.csv')\n",
    "    #test_paths.append(f'../original/{partition}/down_sampled/test/{partition}.csv')\n",
    "    #val_paths.append(f'../original/{partition}/down_sampled/val/{partition}.csv')\n",
    "    paths.append(f'../test/{partition}/down_sampled/new_downsampled_{partition}.csv')\n",
    "\n",
    "\n",
    "X_trains, y_trains, X_tests, y_tests = read_and_split_data(partitions, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZW4dwVAwSVI"
   },
   "source": [
    "### Get the label in integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rb8dLEYSwRfs",
    "outputId": "98d7ae5d-b076-4a42-ad15-e6dff7cacc49"
   },
   "outputs": [],
   "source": [
    "def manipulate_data(ytrains, ytests):\n",
    "    \n",
    "    # Factorize the current column in the training data\n",
    "    codes, uniques = pd.factorize(ytrains)\n",
    "    ytrains = codes\n",
    "\n",
    "    # Create a mapping from string values to their corresponding codes for the training data\n",
    "    mapping = {value: code for code, value in enumerate(uniques)}\n",
    "\n",
    "    # Factorize the current column in the training data\n",
    "    codes, uniques = pd.factorize(ytests)\n",
    "    ytests = codes\n",
    "\n",
    "    # Create a mapping from string values to their corresponding codes for the training data\n",
    "    mapping = {value: code for code, value in enumerate(uniques)}\n",
    "    \n",
    "    return ytrains, ytests\n",
    "\n",
    "\n",
    "for i, partition in enumerate(y_trains):\n",
    "    y_trains[i], y_tests[i] = manipulate_data(partition, y_tests[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def find_best_xgboost(input, truth):\n",
    "    n_estimators = [5, 10, 20, 50, 100, 150, 200, 300, 500] #[int(x) for x in np.linspace(start=10, stop=2000, num=10)]\n",
    "    learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "    subsample = [0.5, 0.7, 1.0]\n",
    "    max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "    param_grid_gb = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"subsample\": subsample,\n",
    "        \"max_depth\": max_depth,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    rs_gb = RandomizedSearchCV(\n",
    "        estimator=gbc,\n",
    "        param_distributions=param_grid_gb,\n",
    "        scoring=None,\n",
    "        refit='f1',\n",
    "        n_iter=10,\n",
    "        return_train_score=True,\n",
    "        cv=None,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    gb_train = rs_gb.fit(input, truth)\n",
    "\n",
    "    best_gb = rs_gb.best_estimator_\n",
    "    best_gb_index = rs_gb.best_index_\n",
    "    print(\"Best params: \", best_gb)\n",
    "    return best_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accuracy(best_gb, year, X, y):\n",
    "    y_pred_gbc = best_gb.predict(X)\n",
    "    accuracy_gbc = accuracy_score(y, y_pred_gbc)\n",
    "    print(f\"Accuracy: {accuracy_gbc * 100:.2f}% for year {year}\")\n",
    "    return accuracy_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params:  GradientBoostingClassifier(learning_rate=0.01, max_depth=9, n_estimators=500,\n",
      "                           random_state=42, subsample=0.7)\n",
      "Accuracy: 4.04% for year data_1970_80\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test_accs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(partitions):\n\u001b[1;32m----> 5\u001b[0m     best_gb_model \u001b[38;5;241m=\u001b[39m find_best_xgboost(X_trains[i], y_trains[i])\n\u001b[0;32m      6\u001b[0m     best_gb_models\u001b[38;5;241m.\u001b[39mappend(best_gb_model)\n\u001b[0;32m      8\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m predict_accuracy(best_gb_model, year, X_tests[i], y_tests[i])\n",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m, in \u001b[0;36mfind_best_xgboost\u001b[1;34m(input, truth)\u001b[0m\n\u001b[0;32m     22\u001b[0m rs_gb \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     23\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mgbc,\n\u001b[0;32m     24\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid_gb,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m gb_train \u001b[38;5;241m=\u001b[39m rs_gb\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28minput\u001b[39m, truth)\n\u001b[0;32m     37\u001b[0m best_gb \u001b[38;5;241m=\u001b[39m rs_gb\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     38\u001b[0m best_gb_index \u001b[38;5;241m=\u001b[39m rs_gb\u001b[38;5;241m.\u001b[39mbest_index_\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_gb_models = []\n",
    "test_accs = []\n",
    "\n",
    "for i, year in enumerate(partitions):\n",
    "    best_gb_model = find_best_xgboost(X_trains[i], y_trains[i])\n",
    "    best_gb_models.append(best_gb_model)\n",
    "    \n",
    "    test_acc = predict_accuracy(best_gb_model, year, X_tests[i], y_tests[i])\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_best_rf(X_train, y_train):\n",
    "     params = {\n",
    "          'criterion': [\"gini\", \"entropy\"],\n",
    "          'n_estimators': [5, 10, 20, 50, 100, 150, 200, 300, 500],\n",
    "          'max_depth': [1, 2,3, 4,5,6,7,8,9,10,11, 12],\n",
    "          'max_features': ['sqrt', 'log2']\n",
    "          }\n",
    "\n",
    "     rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "     grid_search =GridSearchCV(estimator=rf_classifier, param_grid=params, cv=None)\n",
    "\n",
    "     grid_search.fit(X_train, y_train)\n",
    "     best_dt = grid_search.best_estimator_\n",
    "     return best_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rf(best_dt, X_test, y_test):\n",
    "    y_pred_rf = best_dt.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    return acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_models = []\n",
    "test_accs_rf = []\n",
    "\n",
    "for i, year in enumerate(partitions):\n",
    "    best_rf_model = find_best_rf(X_trains[i], y_trains[i])\n",
    "    best_rf_models.append(best_rf_model)\n",
    "    \n",
    "    test_acc_rf = predict_accuracy(best_rf_model, year, X_tests[i], y_tests[i])\n",
    "    test_accs_rf.append(test_acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_path = \"../down_sampled/new_downsampled_data_1970_80_1.csv\"\n",
    "hej = pd.read_csv(working_path, encoding='ISO-8859-1')\n",
    "print(hej.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_path = \"../test/data_1970_80/down_sampled/new_downsampled_data_1970_80.csv\"\n",
    "t_data = pd.read_csv(working_path, encoding='ISO-8859-1')\n",
    "print(t_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_path = \"../down_sampled/new_downsampled_data_1970_80_1.csv\"\n",
    "t_data = pd.read_csv(working_path, encoding='ISO-8859-1')\n",
    "t_size = int(np.floor(len(t_data) * 0.8))\n",
    "t_df_train = t_data.iloc[:t_size]\n",
    "t_df_test = t_data.iloc[int(np.floor(t_size+ len(t_data) * 0.1)):]\n",
    "\n",
    "t_df_train, t_df_test = manipulate_data(t_df_train, t_df_test)\n",
    "\n",
    "t_df_train_y = np.array(t_df_train['enc_group'])\n",
    "t_df_train_X = t_df_train.drop(columns=[\"enc_group\"])\n",
    "\n",
    "t_df_test_y =np.array(t_df_test['enc_group'])\n",
    "t_df_test_X = t_df_test.drop(columns=[\"enc_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_best_rf = find_best_rf(t_df_train_X, t_df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acccc = predict_accuracy(t_best_rf, \"70 to 80\", t_df_test_X, t_df_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and validation data\n",
    "y_train_pred = dt_classifier.predict(X_train)\n",
    "y_val_pred = dt_classifier.predict(X_val)\n",
    "y_test_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nTraining Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nValidation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "val_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nTest Classification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-hgdXVN6m4h",
    "outputId": "885c6d97-5fba-42ee-92fc-7570cefedbbc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the training dataset\n",
    "# train_df = pd.read_csv('train_dataset.csv')  # Replace with your actual file path for the training data\n",
    "# Assuming the last column is the target variable for the training dataset\n",
    "# X_train = train_df.iloc[:, :-1]\n",
    "# y_train = train_df.iloc[:, -1]\n",
    "\n",
    "# Load the validation dataset\n",
    "# val_df = pd.read_csv('validation_dataset.csv')  # Replace with your actual file path for the validation data\n",
    "# Assuming the last column is the target variable for the validation dataset\n",
    "# X_val = val_df.iloc[:, :-1]\n",
    "# y_val = val_df.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Initialize the Decision Tree Classifier with max_depth to prevent overfitting\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# # Initialize the Decision Tree Classifier with max_depth\n",
    "# dt_classifier = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and validation data\n",
    "y_train_pred = dt_classifier.predict(X_train)\n",
    "y_val_pred = dt_classifier.predict(X_val)\n",
    "y_test_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nTraining Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nValidation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "# print(\"\\nTest Classification Report:\\n\", classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "e9JjcS1jGIpb",
    "outputId": "0fc0158e-ffb0-417c-8b72-2c70ac819866"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True')\n",
    "  plt.xlabel('Predicted')\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def count_matches(labels, preds):\n",
    "    #labels = labels.argmax(axis=1)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import average_precision_score,accuracy_score\n",
    "    import pandas as pd\n",
    "    label = pd.DataFrame(labels)\n",
    "    pred = pd.DataFrame(preds)\n",
    "    # map_label = {'negative':1, 'positive':0}\n",
    "    # label[0] = label[0].apply(lambda x: map_label[x])\n",
    "    # pred[0] = pred[0].apply(lambda x: map_label[x])\n",
    "    # print('ROC-AUC', roc_auc_score(label, pred))\n",
    "    # print('precision_recall_curve', average_precision_score(label, pred))\n",
    "    from sklearn.metrics import f1_score\n",
    "    print('macro f1_score', f1_score(labels, preds, average='macro'))\n",
    "    print('micro f1_score', f1_score(labels, preds, average='micro'))\n",
    "    print('accuracy', accuracy_score(labels, preds))\n",
    "    print('f1_score', f1_score(labels, preds, average='weighted'))\n",
    "    print(classification_report(labels, preds))\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    show_confusion_matrix(df_cm)\n",
    "    return sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
    "num_matches = count_matches( y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "jOmLmt4ropkz",
    "outputId": "63f19a27-3104-485b-94cf-c6c3d41d13a5"
   },
   "outputs": [],
   "source": [
    "macro f1_score 0.014814814814814814\n",
    "micro f1_score 0.07537688442211055\n",
    "accuracy 0.07537688442211055\n",
    "f1_score 0.01675041876046901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IabN7N4XQf5X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
