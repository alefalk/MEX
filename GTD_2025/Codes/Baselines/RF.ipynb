{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape trainp1 (783, 25)\n",
      "shape testp1 (338, 25)\n",
      "shape trainp2 (6647, 25)\n",
      "shape testp2 (2847, 25)\n",
      "shape trainp3 (1061, 25)\n",
      "shape testp3 (452, 25)\n",
      "shape trainp4 (4585, 25)\n",
      "shape testp4 (1964, 25)\n"
     ]
    }
   ],
   "source": [
    "trains = ['trainp1', 'trainp2', 'trainp3', 'trainp4']\n",
    "tests = ['testp1', 'testp2', 'testp3', 'testp4']\n",
    "dir = '../CleanPartitions/'\n",
    "\n",
    "traindatas = []\n",
    "testdatas = []\n",
    "\n",
    "for i, partition in enumerate(trains):\n",
    "    trainpath = f'{dir}{trains[i]}.csv'\n",
    "    testpath = f'{dir}{tests[i]}.csv'\n",
    "\n",
    "    traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "    testdata = pd.read_csv(testpath, encoding='ISO-8859-1')\n",
    "    \n",
    "    if 'attack_date' in traindata.columns:\n",
    "        traindata = traindata.drop(columns=['attack_date'])\n",
    "\n",
    "    if 'attack_date' in testdata.columns:\n",
    "        testdata = testdata.drop(columns=['attack_date'])\n",
    "\n",
    "\n",
    "    traindatas.append(traindata)\n",
    "    testdatas.append(testdata)\n",
    "\n",
    "    print(f'shape {trains[i]}', traindata.shape)\n",
    "    print(f'shape {tests[i]}', testdata.shape)\n",
    "#trainpath = '../CleanPartitions/trainp1.csv'\n",
    "#testpath = '../CleanPartitions/testp1.csv'\n",
    "#traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "#testdata = pd.read_csv(testpath, encoding='ISO-8859-1')\n",
    "#print(traindata.shape)\n",
    "#testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
       "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
       "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
       "       'gname', 'individual', 'weaptype1', 'nkill', 'property', 'ishostkid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindatas[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdata['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dftrain, dftest):\n",
    "    Ytrain = dftrain['gname']\n",
    "    Xtrain = dftrain.drop(columns=['gname'])\n",
    "    Ytest = dftest['gname']\n",
    "    Xtest = dftest.drop(columns=['gname'])\n",
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "def find_best_rfc(Xtrain, Ytrain):\n",
    "     n_estimators = [5, 10, 20, 50, 100, 150, 200, 300, 500] #[int(x) for x in np.linspace(start=10, stop=2000, num=10)]\n",
    "     learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "     subsample = [0.5, 0.7, 1.0]\n",
    "     max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "     params = {\n",
    "          'criterion': [\"gini\", \"entropy\"],\n",
    "          'n_estimators': [200, 300, 500],\n",
    "          'max_depth': [2, 5, 10, 15, 20],\n",
    "          'max_features': ['sqrt', 'log2']\n",
    "          }\n",
    "\n",
    "     rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "     tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "     grid_search =GridSearchCV(estimator=rfc, param_grid=params, cv = tscv)\n",
    "\n",
    "     grid_search.fit(Xtrain, Ytrain)\n",
    "     best_rfc = grid_search.best_estimator_\n",
    "     #print(best_dt)\n",
    "     return best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_rfc = best_dt.predict(Xtestp1)\n",
    "#accuracy_gbc = accuracy_score(Ytestp1, y_pred_rfc)\n",
    "#print(f\"Accuracy: {accuracy_gbc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best rfc for parition 1\n",
      "---------------------------------\n",
      "Finding best rfc for parition 2\n",
      "---------------------------------\n",
      "Finding best rfc for parition 3\n",
      "---------------------------------\n",
      "Finding best rfc for parition 4\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_rfcs = []\n",
    "truths = []\n",
    "Xtests = []\n",
    "for i in range(len(traindatas)):\n",
    "    Xtrain, Ytrain, Xtest, Ytest = split_data(traindatas[i], testdatas[i])\n",
    "    print(f'Finding best rfc for parition {i+1}')\n",
    "    best_rfc = find_best_rfc(Xtrain, Ytrain)\n",
    "    print('---------------------------------')\n",
    "    best_rfcs.append(best_rfc)\n",
    "    truths.append(Ytest)\n",
    "    Xtests.append(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition 1:\n",
      "Accuracy: 72.78%\n",
      "-------------------------------------------------\n",
      "partition 2:\n",
      "Accuracy: 99.82%\n",
      "-------------------------------------------------\n",
      "partition 3:\n",
      "Accuracy: 100.00%\n",
      "-------------------------------------------------\n",
      "partition 4:\n",
      "Accuracy: 100.00%\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i in range(len(Xtests)):\n",
    "    print(f'partition {i+1}:')\n",
    "    y_pred_rfc = best_rfcs[i].predict(Xtests[i])\n",
    "    accuracy_rfc = accuracy_score(truths[i], y_pred_rfc)\n",
    "    accuracies.append(accuracy_rfc)\n",
    "    print(f\"Accuracy: {accuracy_rfc * 100:.2f}%\")\n",
    "    print('-------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(Ytestp1, y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_report(Ytestp1, y_pred_rfc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
